{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This code does 3 things\r\n",
    "1) Balances dataset\r\n",
    "2) Cross validation based on inter-patient method\r\n",
    "3) Train on simple classifiers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import math\r\n",
    "from sklearn.utils import resample\r\n",
    "from sklearn.model_selection import LeavePGroupsOut\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "from sklearn import tree\r\n",
    "from scipy.stats import skew\r\n",
    "from collections import Counter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Helper functions\r\n",
    "def get_sleep_info_per_patient(df):\r\n",
    "    pids = df['pid'].unique()\r\n",
    "    info = []\r\n",
    "    for pid in pids:\r\n",
    "    #for pid, i in zip(pids, range(1)): # debugging\r\n",
    "        pid_df = df.loc[df['pid'] == pid]\r\n",
    "        W = (pid_df.loc[df['sleep_stage'] == 0]).shape[0]\r\n",
    "        S1 = (pid_df.loc[df['sleep_stage'] == 1]).shape[0]\r\n",
    "        S2 = (pid_df.loc[df['sleep_stage'] == 2]).shape[0]\r\n",
    "        SWS = (pid_df.loc[df['sleep_stage'] == 3]).shape[0]\r\n",
    "        R = (pid_df.loc[df['sleep_stage'] == 4]).shape[0]\r\n",
    "        assert((W + S1 + S2 + SWS + R) == pid_df.shape[0])\r\n",
    "        info.append([pid, W, S1, S2, SWS, R])\r\n",
    "\r\n",
    "    return info\r\n",
    "\r\n",
    "def remove_patients_with_missing_stages(df, info):\r\n",
    "    bad_patients = [p[0] for p in info if 0 in p[1:None]]\r\n",
    "    for pid in bad_patients:\r\n",
    "        df = df.drop(df[df.pid == pid].index)\r\n",
    "    return df\r\n",
    "\r\n",
    "def remove_extra_patients(df, num_to_remove):\r\n",
    "    num_to_remove *= -1\r\n",
    "    bad_patients = df['pid'].value_counts().index.tolist()[num_to_remove:None]\r\n",
    "    for pid in bad_patients:\r\n",
    "        df = df.drop(df[df.pid == pid].index)\r\n",
    "    return df\r\n",
    "\r\n",
    "def resample_df(df, info):\r\n",
    "    threshold = math.ceil(np.mean([np.mean([epoch[1:None] for epoch in info])]))\r\n",
    "    df_new = pd.DataFrame()\r\n",
    "    pids = df['pid'].unique()\r\n",
    "    for pid in pids:\r\n",
    "        df_pid = df.loc[df['pid'] == pid]\r\n",
    "        for sleep_stage in range(0, 5):\r\n",
    "            df_epoch = df_pid.loc[df_pid['sleep_stage'] == sleep_stage]\r\n",
    "            if df_epoch.shape[0] > threshold:\r\n",
    "                df_epoch = resample(df_epoch, n_samples = threshold, replace = False, random_state = 42)\r\n",
    "            else:\r\n",
    "                df_epoch = resample(df_epoch, n_samples = threshold, replace = True,  random_state = 42)\r\n",
    "            #print(df_epoch)\r\n",
    "            df_new = pd.concat([df_new, df_epoch])\r\n",
    "    num_classes = 5\r\n",
    "    assert(df_new['sleep_stage'].nunique() == num_classes)    # 5 output classes\r\n",
    "    a = [x for x in df_new['sleep_stage'].value_counts()]\r\n",
    "    b = threshold * len(pids)\r\n",
    "    assert(a == b for a in a)  # Ensure each patient in resampled dataset has equal distribution of sleep stage classes\r\n",
    "\r\n",
    "    return df_new\r\n",
    "\r\n",
    "def transform(X, Y):\r\n",
    "    #print(np.min(X))\r\n",
    "    assert(np.min(X) > 0)\r\n",
    "\r\n",
    "    X0 = X\r\n",
    "    X1 = np.log10(X0)\r\n",
    "    X0 = (X0-np.mean(X0, axis=0))/np.std(X0, axis=0)\r\n",
    "    X1 = (X1-np.mean(X1, axis=0))/np.std(X1, axis=0)\r\n",
    "\r\n",
    "    Nepochs, Nfeatures = X.shape\r\n",
    "    print(X.shape)\r\n",
    "\r\n",
    "    # reduce skew\r\n",
    "    X1_skew = skew(X1, axis=0)\r\n",
    "    X0_skew = skew(X0, axis=0)\r\n",
    "    skew_delta = np.abs(X0_skew)-np.abs(X1_skew)\r\n",
    "    skew_delta = skew_delta\r\n",
    "    #indices where we have non-beneficial log transform\r\n",
    "    bad_log_i = np.where(skew_delta < 0)\r\n",
    "    print(bad_log_i)\r\n",
    "\r\n",
    "    # # plot effect of log transform\r\n",
    "    # plt.figure()\r\n",
    "    # plt.scatter(np.arange(Nfeatures), skew_delta)\r\n",
    "    # plt.axhline(0, c=\"black\", linestyle=\"--\")\r\n",
    "    # plt.title(\"Skewness improvement with log transform\")\r\n",
    "    # plt.show()\r\n",
    "\r\n",
    "    # i = np.argmax(np.abs(X1_skew))\r\n",
    "    # plt.figure()\r\n",
    "    # _ = plt.hist(X1[:,i], bins=100, label=\"Log transform\")\r\n",
    "    # _ = plt.hist(X0[:,i], bins=100, label=\"Original\")\r\n",
    "    # plt.legend()\r\n",
    "    # plt.title(f\"Histogram of worst skewness after log transform - X{i}\")\r\n",
    "    # plt.show()\r\n",
    "\r\n",
    "    # i = np.argmin(np.abs(X1_skew))\r\n",
    "    # plt.figure()\r\n",
    "    # _ = plt.hist(X1[:,i], bins=100, label=\"Log transform\")\r\n",
    "    # _ = plt.hist(X0[:,i], bins=100, label=\"Original\")\r\n",
    "    # plt.legend()\r\n",
    "    # plt.title(f\"Histogram of best skewness after log transform - X{i}\")\r\n",
    "    # plt.show()\r\n",
    "\r\n",
    "    # ignore log transform where it worsens skew\r\n",
    "    X1[:,bad_log_i] = X0[:,bad_log_i]\r\n",
    "    Y1 = Y\r\n",
    "\r\n",
    "    return X1, Y1\r\n",
    "\r\n",
    "# Does the following:\r\n",
    "# 1) Obtain number of epochs per sleep stage per patient\r\n",
    "# 2) Filter out patients with a missing sleep stage (79 -> 68)\r\n",
    "# 3) Reduce last 2 patients (68 -> 66) so 6-Fold CV can be performed later\r\n",
    "# 4) Resample based on average number of epochs per sleep stage averaged across all patients. This comes out to be 247 epochs per sleep stage per patient.\r\n",
    "def rebalance_df(df):\r\n",
    "    train_size = 44\r\n",
    "    valid_size = 11\r\n",
    "    test_size = 11\r\n",
    "    total_size = train_size + valid_size + test_size # = 66\r\n",
    "\r\n",
    "    info = get_sleep_info_per_patient(df)\r\n",
    "    df = remove_patients_with_missing_stages(df, info)\r\n",
    "    assert(df['pid'].nunique() >= total_size)\r\n",
    "    df = remove_extra_patients(df, df['pid'].nunique() - total_size)\r\n",
    "\r\n",
    "    info = get_sleep_info_per_patient(df)\r\n",
    "    df = resample_df(df, info)\r\n",
    "    return df\r\n",
    "\r\n",
    "def df_to_array(df):\r\n",
    "    X = []\r\n",
    "    Y = []\r\n",
    "    groups = []\r\n",
    "    pids = df['pid'].unique()\r\n",
    "    pid_to_group = {pid: x % 6 for (pid, x) in zip(pids, range(66))}\r\n",
    "\r\n",
    "    for row in df.to_numpy():\r\n",
    "        X.append(row[1:-1])\r\n",
    "        Y.append(int(row[-1]))\r\n",
    "        groups.append(pid_to_group[row[0]])\r\n",
    "\r\n",
    "    X = np.asarray(X)\r\n",
    "    Y = np.asarray(Y)       \r\n",
    "    groups = np.asarray(groups)\r\n",
    "    return X, Y, groups\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# (Change this if needed) load csv file with epoch features\r\n",
    "data_csv = 'E:/HDD documents/University/comp9417/comp9417-project-21t2/data/subband_data.csv'\r\n",
    "df = pd.read_csv(data_csv)\r\n",
    "df = df.dropna()    # there should not be any nan values anyway\r\n",
    "\r\n",
    "df = rebalance_df(df)\r\n",
    "X, Y, groups = df_to_array(df)\r\n",
    "X1, Y1 = transform(X, Y)\r\n",
    "# %%\r\n",
    "# split into training and testing\r\n",
    "lpgo = LeavePGroupsOut(n_groups = 1)\r\n",
    "lpgo.get_n_splits(X1, Y1, groups)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(81510, 22)\n",
      "(array([12], dtype=int64),)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "for train_valid_index, test_index in lpgo.split(X1, Y1, groups):    # returns generators\r\n",
    "    X_train_valid = X1[train_valid_index]\r\n",
    "    y_train_valid = Y1[train_valid_index]\r\n",
    "    X_test = X1[test_index]\r\n",
    "    y_test = Y1[test_index]\r\n",
    "    # print(f'X_train {X[train_valid_index].shape} y_train_valid {y[train_valid_index].shape} X_test {X[test_index].shape} y_test {y[test_index].shape}')\r\n",
    "\r\n",
    "    # Put classifiers and run training, validation, and testing below here within this loop\r\n",
    "\r\n",
    "    clf = LogisticRegression(max_iter=1000)\r\n",
    "    clf = clf.fit(X_train_valid, y_train_valid)\r\n",
    "\r\n",
    "    y_pred = clf.predict(X_train_valid)\r\n",
    "    train_acc = np.mean(y_pred == y_train_valid)\r\n",
    "    y_pred = clf.predict(X_test)\r\n",
    "    test_acc = np.mean(y_pred == y_test)\r\n",
    "\r\n",
    "    print(train_acc)\r\n",
    "    print(test_acc) # approx 60-70% with inter-patient\r\n",
    "\r\n",
    "    plt.imshow(clf.coef_, cmap=\"PRGn\")\r\n",
    "    #plt.colorbar()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6773794626426205\n",
      "0.6640412219359588\n",
      "0.6824880382775119\n",
      "0.6494663231505337\n",
      "0.6745528156054472\n",
      "0.6703717335296283\n",
      "0.6753183658446816\n",
      "0.6674273095325727\n",
      "0.6765255796834744\n",
      "0.6703717335296283\n",
      "0.6778652926021347\n",
      "0.6549135075450865\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Old code for classifiers below"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pid = 0\r\n",
    "mask = (df['pid'] == pid)\r\n",
    "x = X[mask]\r\n",
    "y = Y[mask]\r\n",
    "\r\n",
    "# Plot our true and predicted hypnogram\r\n",
    "len_slice = 100\r\n",
    "n_slice = 7\r\n",
    "i = np.arange(0, len_slice) + len_slice*n_slice\r\n",
    "#i = np.arange(0, y.shape[0])\r\n",
    "epoch_time = 30\r\n",
    "t = i*(epoch_time/3600) # hours\r\n",
    "\r\n",
    "y_true = y\r\n",
    "y_pred =  clf.predict(x)\r\n",
    "print(np.mean(y_true == y_pred))\r\n",
    "print(np.mean(y_true[i] == y_pred[i]))\r\n",
    "\r\n",
    "fig = plt.figure(figsize=(20,10))\r\n",
    "plt.step(t, y_true[i], label=\"ytrue\")\r\n",
    "plt.step(t, y_pred[i], linestyle=\"--\", label=\"ypred\")\r\n",
    "_ = plt.yticks(np.unique(y))\r\n",
    "plt.grid(True)\r\n",
    "plt.legend()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "clf = SVC()\r\n",
    "clf.fit(Xtrain, Ytrain)\r\n",
    "\r\n",
    "ypred = clf.predict(Xtrain)\r\n",
    "train_acc = np.mean(ypred == Ytrain)\r\n",
    "ypred = clf.predict(Xtest)\r\n",
    "test_acc = np.mean(ypred == Ytest)\r\n",
    "print(train_acc)\r\n",
    "print(test_acc)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "pid = 0\r\n",
    "mask = (df['pid'] == pid)\r\n",
    "x = X[mask]\r\n",
    "y = Y[mask]\r\n",
    "\r\n",
    "# Plot our true and predicted hypnogram\r\n",
    "len_slice = 100\r\n",
    "n_slice = 7\r\n",
    "i = np.arange(0, len_slice) + len_slice*n_slice\r\n",
    "#i = np.arange(0, y.shape[0])\r\n",
    "epoch_time = 30\r\n",
    "t = i*(epoch_time/3600) # hours\r\n",
    "\r\n",
    "y_true = y\r\n",
    "y_pred =  clf.predict(x)\r\n",
    "print(np.mean(y_true == y_pred))\r\n",
    "print(np.mean(y_true[i] == y_pred[i]))\r\n",
    "\r\n",
    "fig = plt.figure(figsize=(20,10))\r\n",
    "plt.step(t, y_true[i], label=\"ytrue\")\r\n",
    "plt.step(t, y_pred[i], linestyle=\"--\", label=\"ypred\")\r\n",
    "_ = plt.yticks(np.unique(y))\r\n",
    "plt.grid(True)\r\n",
    "plt.legend()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "interpreter": {
   "hash": "ca416d46cdc90f0d92f8c4cf1d504b54208493fa79b1d6139d129445d45642e5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}